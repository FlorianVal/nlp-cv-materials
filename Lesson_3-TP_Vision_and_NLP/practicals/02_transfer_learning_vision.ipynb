{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# TP 3 - Partie 2 : Transfer Learning en Vision üñºÔ∏è\n",
    "\n",
    "Dans ce notebook, nous allons appliquer le transfer learning √† la vision par ordinateur.\n",
    "\n",
    "**Objectifs :**\n",
    "1. Charger un mod√®le de vision pr√©-entra√Æn√© l√©ger\n",
    "2. Comprendre la diff√©rence entre Feature Extraction et Fine-tuning\n",
    "3. Entra√Æner sur un nouveau dataset\n",
    "4. Visualiser les pr√©dictions\n",
    "\n",
    "‚ö†Ô∏è **Contrainte mat√©rielle** : Nous utilisons des mod√®les l√©gers (ResNet18 ~11M params) adapt√©s aux PCs de facult√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device : {device}\")\n",
    "\n",
    "# Fixer les seeds pour la reproductibilit√©\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset",
   "metadata": {},
   "source": [
    "## 2. Chargement du dataset\n",
    "\n",
    "Nous utilisons **CIFAR-10** (10 classes, images 32√ó32) avec un sous-ensemble pour l'entra√Ænement rapide.\n",
    "\n",
    "Les classes : avion, voiture, oiseau, chat, cerf, chien, grenouille, cheval, bateau, camion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes CIFAR-10\n",
    "CLASSES = ['avion', 'voiture', 'oiseau', 'chat', 'cerf', \n",
    "           'chien', 'grenouille', 'cheval', 'bateau', 'camion']\n",
    "\n",
    "# Transformations pour le train (data augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet attend 224√ó224\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformations pour le test\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# T√©l√©charger CIFAR-10\n",
    "print(\"T√©l√©chargement de CIFAR-10...\")\n",
    "full_train = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=train_transform\n",
    ")\n",
    "full_test = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "# R√©duire la taille pour l'entra√Ænement rapide\n",
    "# Prendre seulement 1000 images par classe pour l'entra√Ænement\n",
    "train_indices = []\n",
    "for class_idx in range(10):\n",
    "    class_indices = [i for i, (_, label) in enumerate(full_train) if label == class_idx]\n",
    "    train_indices.extend(class_indices[:1000])  # 1000 par classe\n",
    "\n",
    "train_dataset = Subset(full_train, train_indices)\n",
    "test_dataset = full_test  # Garder tout le test\n",
    "\n",
    "print(f\"\\nDataset r√©duit :\")\n",
    "print(f\"   Entra√Ænement : {len(train_dataset)} images\")\n",
    "print(f\"   Test : {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser quelques exemples\n",
    "def denormalize(tensor):\n",
    "    \"\"\"Enlever la normalisation pour l'affichage\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Trouver une image de la classe i\n",
    "    for img, label in train_dataset:\n",
    "        if label == i:\n",
    "            img = denormalize(img)\n",
    "            ax.imshow(img.permute(1, 2, 0).clamp(0, 1))\n",
    "            ax.set_title(CLASSES[i])\n",
    "            ax.axis('off')\n",
    "            break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataloaders",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataloaders_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Batches d'entra√Ænement : {len(train_loader)}\")\n",
    "print(f\"Batches de test : {len(test_loader)}\")\n",
    "\n",
    "# V√©rifier la shape d'un batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"\\nShape d'un batch d'images : {images.shape}\")\n",
    "print(f\"   ‚Üí [batch_size={images.shape[0]}, channels={images.shape[1]}, H={images.shape[2]}, W={images.shape[3]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_loading",
   "metadata": {},
   "source": [
    "## 3. Chargement d'un mod√®le pr√©-entra√Æn√©\n",
    "\n",
    "Nous utilisons **ResNet18**, un mod√®le l√©ger (~11M param√®tres) pr√©-entra√Æn√© sur ImageNet.\n",
    "\n",
    "**Architecture de ResNet18 :**\n",
    "- 4 blocs r√©siduels (layers)\n",
    "- Skip connections pour √©viter le vanishing gradient\n",
    "- ~11M param√®tres (rapide √† entra√Æner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_resnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger ResNet18 pr√©-entra√Æn√©\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "print(\"=== Architecture ResNet18 ===\")\n",
    "print(resnet)\n",
    "\n",
    "# Compter les param√®tres\n",
    "total = sum(p.numel() for p in resnet.parameters())\n",
    "print(f\"\\nTotal param√®tres : {total:,} (~{total/1e6:.1f}M)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore_resnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorer la structure\n",
    "print(\"=== Structure hi√©rarchique ===\")\n",
    "for name, module in resnet.named_children():\n",
    "    params = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"{name:15s} : {module.__class__.__name__:20s} ({params:,} params)\")\n",
    "\n",
    "print(\"\\n=== La derni√®re couche (classifier) ===\")\n",
    "print(f\"fc : {resnet.fc}\")\n",
    "print(f\"\\nCette couche a √©t√© entra√Æn√©e pour classifier sur 1000 classes ImageNet.\")\n",
    "print(f\"Nous allons la remplacer pour 10 classes CIFAR-10.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy1",
   "metadata": {},
   "source": [
    "## 4. Strat√©gie 1 : Feature Extraction (Geler le backbone)\n",
    "\n",
    "**Principe :** On garde les poids du mod√®le pr√©-entra√Æn√© fig√©s et on n'entra√Æne que la derni√®re couche (classifier).\n",
    "\n",
    "**Avantages :**\n",
    "- Tr√®s rapide (moins de param√®tres √† entra√Æner)\n",
    "- Peu de donn√©es n√©cessaires\n",
    "- √âvite le overfitting\n",
    "\n",
    "**Cas d'usage :** Petit dataset, ressources limit√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le mod√®le pour feature extraction\n",
    "model_fe = models.resnet18(pretrained=True)\n",
    "\n",
    "# Geler tous les param√®tres du backbone\n",
    "for param in model_fe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Remplacer la derni√®re couche pour 10 classes\n",
    "num_features = model_fe.fc.in_features\n",
    "model_fe.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "# Seuls les param√®tres de la nouvelle couche sont entra√Ænables\n",
    "trainable = sum(p.numel() for p in model_fe.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model_fe.parameters())\n",
    "\n",
    "print(f\"Feature Extraction :\")\n",
    "print(f\"   Param√®tres entra√Ænables : {trainable:,}\")\n",
    "print(f\"   Param√®tres fig√©s : {total - trainable:,}\")\n",
    "print(f\"   Taux d'entra√Ænement : {trainable/total*100:.2f}%\")\n",
    "\n",
    "model_fe = model_fe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'entra√Ænement\n",
    "def train_model(model, train_loader, test_loader, epochs=5, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    train_accs, test_accs = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Entra√Ænement\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # √âvaluation\n",
    "        model.eval()\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, test_losses, train_accs, test_accs\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Entra√Æner (3 epochs pour aller vite)\n",
    "print(\"\\n=== Entra√Ænement Feature Extraction ===\")\n",
    "history_fe = train_model(model_fe, train_loader, test_loader, epochs=3, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy2",
   "metadata": {},
   "source": [
    "## 5. Strat√©gie 2 : Fine-tuning complet\n",
    "\n",
    "**Principe :** On d√©g√®le tout le mod√®le et on entra√Æne avec un learning rate faible.\n",
    "\n",
    "**Avantages :**\n",
    "- Meilleures performances\n",
    "- Adaptation compl√®te au nouveau domaine\n",
    "\n",
    "**Inconv√©nients :**\n",
    "- Plus lent\n",
    "- Risque de overfitting\n",
    "- N√©cessite plus de donn√©es\n",
    "\n",
    "**Astuce :** Utiliser un learning rate plus faible pour les couches pr√©-entra√Æn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finetuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le mod√®le pour fine-tuning\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# Remplacer le classifier (tous les param√®tres sont entra√Ænables par d√©faut)\n",
    "num_features = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_features, 10)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "trainable = sum(p.numel() for p in model_ft.parameters() if p.requires_grad)\n",
    "print(f\"Fine-tuning : {trainable:,} param√®tres entra√Ænables\")\n",
    "\n",
    "# Entra√Æner avec un LR plus faible\n",
    "print(\"\\n=== Entra√Ænement Fine-tuning ===\")\n",
    "history_ft = train_model(model_ft, train_loader, test_loader, epochs=3, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## 6. Comparaison des deux strat√©gies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser la comparaison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_fe[2], label='Feature Extraction', marker='o')\n",
    "axes[0].plot(history_ft[2], label='Fine-tuning', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy (%)')\n",
    "axes[0].set_title('Accuracy sur le train')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Test accuracy\n",
    "axes[1].plot(history_fe[3], label='Feature Extraction', marker='o')\n",
    "axes[1].plot(history_ft[3], label='Fine-tuning', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Accuracy sur le test')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== R√©sultats finaux ===\")\n",
    "print(f\"Feature Extraction - Test Acc : {history_fe[3][-1]:.2f}%\")\n",
    "print(f\"Fine-tuning        - Test Acc : {history_ft[3][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## 7. Visualisation des pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser quelques pr√©dictions\n",
    "def visualize_predictions(model, dataset, num_images=10):\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
    "    \n",
    "    for idx, ax in zip(indices, axes.flat):\n",
    "        image, label = dataset[idx]\n",
    "        \n",
    "        # Pr√©diction\n",
    "        with torch.no_grad():\n",
    "            output = model(image.unsqueeze(0).to(device))\n",
    "            pred = output.argmax(1).item()\n",
    "            probs = torch.softmax(output, dim=1)[0]\n",
    "        \n",
    "        # Afficher\n",
    "        img_display = denormalize(image).permute(1, 2, 0).clamp(0, 1)\n",
    "        ax.imshow(img_display)\n",
    "        color = 'green' if pred == label else 'red'\n",
    "        ax.set_title(f\"Vrai: {CLASSES[label]}\\nPr√©d: {CLASSES[pred]}\\nConf: {probs[pred]:.1%}\", \n",
    "                    color=color)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Pr√©dictions du mod√®le Fine-tuned :\")\n",
    "visualize_predictions(model_ft, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confusion_matrix",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conf_matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la matrice de confusion\n",
    "def get_predictions(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(1).cpu()\n",
    "            \n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "preds, labels = get_predictions(model_ft, test_loader)\n",
    "\n",
    "# Afficher\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "plt.xlabel('Pr√©diction')\n",
    "plt.ylabel('V√©rit√©')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(labels, preds, target_names=CLASSES, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_model",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde et chargement du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le mod√®le\n",
    "save_path = \"./mon_modele_cifar10.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model_ft.state_dict(),\n",
    "    'classes': CLASSES,\n",
    "    'model_name': 'resnet18'\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Mod√®le sauvegard√© : {save_path}\")\n",
    "\n",
    "# Charger le mod√®le\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "# Recr√©er l'architecture\n",
    "loaded_model = models.resnet18(pretrained=False)\n",
    "loaded_model.fc = nn.Linear(loaded_model.fc.in_features, 10)\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "print(\"Mod√®le charg√© avec succ√®s !\")\n",
    "\n",
    "# V√©rifier qu'il fonctionne\n",
    "_, acc = evaluate(loaded_model, test_loader, nn.CrossEntropyLoss())\n",
    "print(f\"Accuracy du mod√®le charg√© : {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recap",
   "metadata": {},
   "source": [
    "## üéØ R√©capitulatif\n",
    "\n",
    "Dans ce notebook, nous avons vu :\n",
    "\n",
    "1. **Chargement de mod√®le pr√©-entra√Æn√©** : ResNet18 depuis `torchvision.models`\n",
    "2. **Feature Extraction** : Geler le backbone, entra√Æner seulement le classifier (rapide)\n",
    "3. **Fine-tuning** : Entra√Æner tout le mod√®le avec un LR faible (meilleures perfs)\n",
    "4. **√âvaluation** : Visualisation des pr√©dictions et matrice de confusion\n",
    "5. **Sauvegarde** : `torch.save()` et `torch.load()`\n",
    "\n",
    "**R√®gles de pouce pour choisir :**\n",
    "- **Petit dataset (<1000 images)** ‚Üí Feature Extraction\n",
    "- **Dataset moyen (1000-10000)** ‚Üí Fine-tuning avec LR faible\n",
    "- **Gros dataset (>10000)** ‚Üí Fine-tuning ou entra√Ænement from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Exercices optionnels\n",
    "\n",
    "1. **Essayer un autre mod√®le** : Remplacer ResNet18 par `mobilenet_v2` (encore plus l√©ger)\n",
    "2. **Data augmentation** : Ajouter plus d'augmentations et observer l'impact\n",
    "3. **Learning rate scheduling** : Utiliser `torch.optim.lr_scheduler` pour r√©duire le LR\n",
    "4. **Early stopping** : Arr√™ter l'entra√Ænement quand la val accuracy stagne\n",
    "5. **Grad-CAM** : Visualiser quelles parties de l'image le mod√®le regarde"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
   "nbformat_minor": 5
}